## 第1章 引言

### 1.1 课题研究背景及意义

视觉作为人类最重要的人体感知方式，获取的信息约占人类接触到的外界信息的 80%。人类已经习惯通过视觉获取图像信息进而处理这些信息。图像是包含信息量较多的一种载体，互联网中有一半以上的流量用于传输图像数据；同时各种图像传感器被应用到人类日常生活中的方方面面，比如手机摄像头、视频监控、CT 扫描仪等，仅仅依靠人眼无法处理不同领域中庞大的图像信息，这就必须利用计算机视觉来处理这些传感器传来的数以 EB 计的信息。计算机视觉的本质是利用计算机配合传感器替代人眼的功能，从生物学角度看，旨在构建人类视觉系统的计算模型；从工程学角度看，旨在构建一个可以执行人类视觉可执行的某些任务的系统[1]。

计算机视觉任务包括目标检测、目标跟踪、图像分割、图像检索、行为识别等，其中目标检测是其它更复杂的任务的基石，主要目的是找出图像中所有感兴趣的目标物体，确定它们的类别并用直观的边界框确定其位置。目标检测融合了图像处理、特征提取、深度学习等多个研究领域的前沿技术，是计算机视觉领域的核心问题之一。由于各种目标有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域极具挑战性的课题。

目前目标检测已广泛应用于自动驾驶、机器人视觉、视频监控等计算机视觉任务中[2]。在自动驾驶任务中，自动车辆需要对采集的图像信息进行处理，识别交通标志、车辆、行人等，精确而实时的目标识别系统对于保障安全驾驶至关重要；在机器人视觉任务中，机器人对真实人类的动作、行为及运动进行识别并产生相应的反馈，从而实现人机交互；在视频监控任务中，如果还采用事后查看和人工监督的方法将无法应对日益增加的视频数据，利用目标检测技术可以对人和物体进行识别，可以快速发现可疑人员，记录人员行为，实现智能化监控。我们知道，在公共场所佩戴口罩可以防止各种呼吸道疾病的传播，同时也能一定程度上的过滤空气中的污染物。随着新冠疫情常态化，如今许多人群密集的区域如电梯、超市、车站等都需要佩戴口罩，但通过人工检查口罩佩戴情况的方式会消耗大量的人力资源。我们可以利用目标识别技术实现一个口罩佩戴检测系统，对佩戴口罩不规范或未戴口罩的人予以提示，同时提高检测效率。

### 1.2 国内外研究概况

#### 1.2.1 传统的目标检测

2001 年 P.Viola 和 M.Jones 首次实现了人脸的实时检测[3]，他们发明的 VJ 检测器采用了最直接的滑动窗口方法：查看图像中所有可能的位置和比例，看能否找到包含人脸的窗口，为了匹配当时的计算能力，他们采用了“积分图像”、“特征选择”和“检测级联”三种技术提高检测速度。 2004 年，David Lowe 完善[4]其于 1999 年提出的尺度不变特征变化匹配（Scale-Invariant Feature Transform，SIFT）[5]算法，该算法提出根据目标的部分的部分特征而不需要描述整个物体就可以实现识别任务的思想，完善后的 SIFI 算法更是对图像尺度和旋转、光照变化以及噪声具有鲁棒性。2005 年N.Dalal 和 B.Triggs 提出了方向梯度直方图(Histogram of Oriented Gradient，HOG)[6]，HOG 改进了 SIFI 和形状上下文（Shape Contexts），为了平衡特征不变性和非线性， HOG 描述符被设计在密集的均匀间隔单元网格上进行计算，并使用重叠的局部对比度归一化来进一步提高精度。此后，SIFT 和 HOG 这样的手工特征是许多目标检测器的基础，结合一些机器学习分类算法如支持向量机（Support Vector Machine，SVM）有较好的检测效果。可变形部件的模型（Deformable Part-based Model，DPM）最初是由P.Felzenszwalb 等[7]于 2008 年提出的，起初是作为 HOG 检测器的扩展，DPM 采用“分而治之”的思想对目标进行检测，训练简单地看作是学习如何正确的分解对象，推理可以看作对不同对象的部件的检测集合。DPM 应用“混合模型”、“硬负挖掘”、“边界盒回归”等技术提高检测精度。2010 年 R.Girshick 等人对 DPM 进行改进[8,9]，引入了级联结构，使得 DPM 检测速度提高了 10 倍。 2012 年，G. E.  Hinton 和他的学生 A.Krizhevsky 提出的 AlexNet 在 ImageNet 比赛中取得的成就为目标检测算法提供了新思路，他们使用了深度卷积神经网络[10]。此后，目标识别算法开始以前所未有的速度发展。

#### 1.2.2 基于深度学习的目标检测

2006 年， Hinton 在《科学》杂志刊文提出了深度学习[11]的概念，但一直到 2011 年，深度学习才迎来大爆发，此后国际上许多知名公司如谷歌、微软、 Facebook 都积极建立研究院进行深度学习这方面的研究。国内紧跟国际潮流，许多公司如百度、阿里、腾讯、华为、小米等也在积极进行深度学习的研究，许多行业如交通[12]、医疗[13]、服务[14]也在积极应用深度学习。百度作为全球最大的中文搜索引擎提供商，利用其得天独厚的数据优势，率先成立国内深度学习研究院， 2014 年又在美国硅谷成立人工智能实验室， 2016 年面向全球开源国内首个开源深度学习框架“PaddlePaddle（飞浆）”，并成功在国内外深度学习领域取得了认可。此外，国内许多高校也纷纷开设深度学习课程，并进行相关研究， 2020 年，清华大学发布国内首个由高校主导并开源的深度学习框架“Jittor（计图）“，推动了深度学习框架国产化的进程。

人工神经网络是模拟人脑神经元的功能的网络结构，深度学习则包含多层人工神经网络。最早的人工神经网络起源于 1943 年的 MCP 人工神经元模型，建立了首个神经网络的数学模型。1958 年感知机诞生， 1989 年，G.E.Hinton 提出了采用非线性激活函数的反向传播算法，有力的推动了神经网络的研究，同年，Y.LuCun 为了检测手写数字[15]发明了LeNet。 1998 年由 LeCun 设计的的 LeNet5[16] 模型标志着卷积神经网络（Convolutional Neural Networks，CNN）真正面世。 2012 年基于 CNN 的 AlexNet 的成就使得大量研究者纷纷研究CNN，研究出许多基于 CNN 的目标检测算法，如图1.1 所示。

![图1.1 从传统目标检测到基于深度学习的目标检测](https://ufile.freewisdom.cn/resources/605a0101/obj-det-development.png)

<center>图1.1 从传统目标检测到基于深度学习的目标检测</center>

 2014 年由 R.Girshick 等提出的 R-CNN[17] 通过选择性搜索提取一组对象候选框，每个候选框都被重新调整成一个固定大小的图像输入到 CNN 中，最后，利用 SVM 分类器对每个区域内的目标进行预测。R-CNN 会在大量（每张图片 2000 多个候选框）重叠的候选框上进行冗余的特征计算，导致检测速度极慢。虽然之后研究者不变改进两阶段检测器，但实时目标检测效果还是差强人意。

 2016 年，J.Redmon 等人提出的 YOLO（You Only Look Once）[18]算法开创了基于回归方法的深度学习目标检测算法，同时 YOLO 也是一种单阶段目标检测算法，实现了端到端的检测。 YOLO 将全图划分成单元格，每个单元格需要对落入其中的目标进行检测，一次性预测所有单元格所含目标的边界框、定位置信度和类别概率。 YOLO 可以处理每秒 45 帧的视频，同时还能有比较好的检测精度，在 PASCAL VOC 数据集上 mAP 能达到63.4%。随后研究者们也推出了其它的单阶段目标检测算法，如SSD（Single Shot MultiBox Detector）[22]等。 2017 年提出的 YOLO v2[19]在 YOLOv1 的基础上修改了基础网络结构，采用 Darknet-19 减少了计算量；增加了批次归一化层，引入了维度聚类的 Anchor Box 机制，采用高分辨率分类器，采用规约的 offset 预测边界框位置，这些改进在提高检测速度的同时显著提升了检测精度，在 VOC 数据集上在和 YOLOv1 差不多的速度下 mAP 达到 78.6%。 2018 年，YOLO v3[20]再次改进了 YOLO 算法，主干网络采用Darknet-53，减少了浮点数运算量；引入特征金字塔多尺度预测以提高定位精准度，采用多标签分类，同时优化损失函数，提高了小目标的检测效果。 YOLO v3 在 MS-COCO 数据集 320× 320 分辨率上， YOLO v3 处理每张图片仅需要22ms，比同分辨率情况的 SSD 快 3 倍，同时 mAP 还比 SSD 高，达到了 28.2%。 2020 年 A.Bochkovskiy 等人改进的 YOLOv4[21] 结合计算机视觉领域多篇优秀论文对 YOLO 进行改进，相比 YOLO v3 提高 10% 的 AP 和12%的FPS，同时使得训练速度更快且更适合于单 GPU 训练。本文将选基于 YOLOv3 模型实现一个实时口罩佩戴检测系统，并改进 YOLO v3 模型的定位损失部分进行对比实验。

### 1.3 研究工作与论文结构
本课题主要研究 YOLO v3 模型，首先会对深入学习 YOLO v3 模型，理解其原理后复现此模型并且实现针对口罩佩戴检测的实时目标检测系统。同时针对 YOLO v3 模型采用 IoU Loss 计算定位损失的方法进行改进，将参考 YOLO v4 模型引入的 CIoU Loss，采用 GIoU/DIoU/CIoU Loss 进行优化，对比优化前后的结果。研究内容细化如下：

(1) 阅读 YOLO 系列以及目标检测相关的论文以熟悉 YOLO 模型和目标检测技术，了解 YOLO 与其它目标检测技术的异同，主要学习 YOLO v3 算法背后的原理，同时参考开源代码进行模型的复现实验。

(2) 研究 YOLO 模型的实际应用，主要是利用 YOLOv3 实现一个实时的目标检测系统，功能是检测口罩佩戴情况，佩戴情况分为好（good）、坏（bad）和无（none），将从网络收集人脸图像和不同人群的口罩图片制作成数据集并训练网络。

(3) YOLO v3 相比于YOLO v1,v2 版本有很大的改进，但是还是有很大的提升空间，本文将参考 YOLO v4 对 IoU 的改进，使用 GIoU/DIoU/CIoU Loss 优化 YOLO v3，采用标准数据集进行实验，查看经过小优化后的 YOLO v3 的检测效果，然后对实验结果进行分析。
