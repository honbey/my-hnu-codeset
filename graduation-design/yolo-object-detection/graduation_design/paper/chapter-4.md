## 第4章 优化改进YOLO v3模型的实验

YOLO 模型自 18 年至今已经有 5 个版本了，本章将参考 YOLO v4 相比于 v3 的其中一个改进措施：GIoU，替换 YOLO v3 的 IoU 为 GIoU，之后再采用 DIoU 和 CIoU 进行实验，实验数据集使用的是 VOC 2007 数据集，每种目标框回归损失均训练 5020 轮，训练后计算 mAP, AP50 等，最后对比分析实验结果。

### 4.1 实验

PASCAL VOC-2007 数据集作为标准数据集，衡量图像分类识别能力的基准，VOC-2007 共包含训练集 5011 幅图像，测试集 4952 幅图像，共计 9963 幅图像，20 个种类（aeroplane, bicycle, bird, boat, bottles, bus, car, cat, chair, cow, diningtable, dog, horse, motorbike, person, pottledplant, sheep, sofa, train, tvmonitor）。本实验将直接使用 VOC-2007 数据集的图像数据，仅针对标签文件的目标框进行归一化处理后得到 darknet 能处理的 txt 文件。
本章实验的硬件与软件环境与上一章的相同。

网络配置文件中采用不同的目标框回归损失，均会训练 5020 轮，在第 4000 和 4500 轮学习率会在降低为原来的十分之一，classes 为 20，最后的输出维度为 75。训练 100 轮需要 9 至 10 分钟，每种目标框回归损失大约用时 8 小时，用最后得到权重文件再使用测试集的 4952 幅图像进行验证，这将得到各类别的 txt 检测结果文件，分别为不带路径与后缀的图片名，该类别的置信度分数，四个绝对坐标值。然后利用 python 脚本将检测结果与数据集中的 xml 注释文件先根据 IoU 阈值进行判断，只有大于阈值的才能被用于计算准确率，这会得到每个类别的 AP50, AP55, ..., AP95，共 10 个 txt 文件，最后再利用另外一个 python 脚本计算 mAP。

### 4.2 实验结果

本章的实验得到 mAP，AP50 等如表4.1 所示，表中的数据均采用 VOC 数据集的规范进行计算。从最终的结果来看，CIoU 拥有最高的准确率，这也符合我们的预期，准确率 mAP 由高到低分别为 CIoU, DIoU, GIoU, IoU，符合预期理论。

|$L\_{loss}$|  mAP| AP50| AP55| AP60| AP65| AP70| AP75| AP80| AP85| AP90| AP95|
|-----------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
|IoU        |31.79|60.65|57.85|53.89|47.86|40.15|30.13|18.40| 7.32| 1.55| 0.07|
|GIoU       |33.28|63.96|61.13|56.43|50.18|42.28|31.49|18.76| 7.20| 1.28| 0.05|
|DIoU       |33.97|64.15|61.44|57.52|51.50|43.50|32.26|19.61| 8.33| 1.30| 0.09|
|CIoU       |34.18|64.43|61.37|57.28|51.72|43.71|33.14|20.30| 8.29| 1.59| 0.09|

<center>表4.1 实验最终数据</center>

### 4.3 实验分析及结论

IoU 的计算过程如下：

输入：任意两个矩形框：$A, B$
输出：IoU

1. $IoU = \frac{|A \cap B|}{|A \cup B|}$


IoU 计算的是预测框和真实框的交集和并集的比值。IoU Loss 在两个物体不相交时不会回传梯度，此时 IoU Loss 为 1，这种情况下无法衡量预测框和真实框的距离。同理，在两框相交的某些情况下至一个框包含另一个框的时候，IoU 也无法很好反映两框的重叠程度，只能表明两框的小大关系，而无法衡量两框的距离；在两框存在包含关系，IoU Loss 为 0，此时预测框与真实框的损失的 IoU Loss 无法进行反向传播，这会导致准确度降低。在两框比较一般的相交情况下，IoU Loss 可以被反向传播。IoU Loss 表达式见公式(2-3)。

GIoU 的计算过程如下：

输入：任意两个矩形框：$A, B$
输出：GIoU

1. 找到 $A,B$ 的最小外接凸形 $C$
2. $IoU = \frac{|A \cap B|}{|A \cup B|}$
3. $GIoU = IoU - \frac{|C-A \cup B|}{|C|}$

GIoU Loss 利用了 IoU Loss 的优点同时努力克服其缺点，GIoU 可以认为是 IoU 的下界，小于等于 IoU。当两框存在包含关系时，GIoU 与 IoU 一样，此时 GIoU Loss 完全退化为 IoU Loss。当两框不相交时，GIoU 能很好的反映两框的距离关系，距离越远，GIoU 越趋向于 -1，此时预测框与真实框的损失可以被反向传播，GIoU Loss 避免了 IoU Loss 在两框不相交时的梯度消失问题。GIoU Loss 相当于在 IoU Loss 在候选框和真实框没有重叠的时候不提供任何移动梯度的情况下引入一个惩罚因子，这个惩罚因子会让预测框向真实框回归。GIoU Loss 表达式见公式(2-4)。

DIoU 的计算过程如下：

输入：任意两个矩形框：$A, B$
输出：DIoU

1. 找到 $A,B$ 的最小外接凸形 $C \belong S \in R^{n}$
2. $IoU = \frac{|A \cap B|}{|A \cup B|}$
3. 计算 $A, B$ 的中心点的欧式距离 $d$
4. 计算 $C$ 的对角线长度 $c$
5. $DIoU = IoU - \frac{d}{c}$

DIoU Loss 在 IoU Loss 的基础上引入另一个惩罚因子，DIoU Loss 考虑了预测框与真实框的欧式距离，这个惩罚因子就是两框的中心点距离与两框最小外接矩形对角线的比值。如此 DIoU Loss 在两框不重叠时，可以为边界框提供移动方向，而且相比于 GIoU Loss 优化两框之间的面积，DIoU Loss 可以直接最小化两框的距离，保证了两框存在包含关系时也能被反向传播，同时收敛速度更快。DIoU Loss 表达式见公式(2-5)。

CIoU 的计算过程如下：

输入：任意两个矩形框：$A, B$
输出：CIoU

1. 找到 $A,B$ 的最小外接凸形 $C \belong S \in R^{n}$
2. $IoU = \frac{|A \cap B|}{|A \cup B|}$
3. 计算 $A, B$ 的中心点的欧式距离 $d$
4. 分别计算 $A, B$ 各自的宽高比 $\frac{w_a}{h_a}, \frac{w_b}{h_b}$
5. 计算 $C$ 的对角线长度 $c$
6. 宽高比一致性的参数 $\nu = \frac{4}{\pi^{2}}\(\arctan\frac{w_a}{h_a}-\arctan\frac{w_b}{h_b}\)^{2}$
7. 平衡比例参数 $\alpha = \frac{\nu}{(1-IoU)+\nu}$
8. $CIoU = IoU - \frac{d}{c} - \alpha \nu$

CIoU Loss 基于 DIoU Loss 改良，相对于 DIoU 考虑预测框和真实框的重叠面积，中心点距离外还考量宽高比。额外引入惩罚因子：宽高比，这会让预测框往两框的重叠区域增多的方向回归。CIoU 全称 Complete-IoU，把目标框回归损失最重要的几何因素都考虑了，达到了最高的准确率，在本章的实验中，mAP 相比 IoU Loss 提升 7.52%，AP75 提升 9.99%（表4.2）。CIoU Loss 表达式见公式(2-6)。

|$L\_{loss}$|   mAP|  AP75|
|-----------|------|------|
|IoU        | 31.79| 30.13|
|GIoU       | 33.28| 31.49|
|相对提升 % | 4.69%| 4.51%|
|DIoU       | 33.97| 32.26|
|相对提升 % | 6.86%| 7.07%|
|CIoU       | 34.18| 33.14|
|相对提升 % | 7.52%| 9.99%|

<center>表4.2 mAP, AP75 相对于 IoU 的提升</center>


本章的实验探讨了不同目标框回归损失的准确率，从实验结果来看，考虑的几何因素越多越能提升准确率，同时也可加快网络的收敛速度。但本实验处于验证目的把训练的批次设置比较小，存在偶然性，最终实验得到 mAP 没有超过 40，同时数据集只使用了 VOC-2007，没有加入 VOC-2012 数据集，这也限制了 mAP 的提升。