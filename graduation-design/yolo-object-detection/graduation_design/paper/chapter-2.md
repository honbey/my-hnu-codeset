## 第2章 预备知识

### 2.1 神经网络与深度学习

最简单的人工神经网络如图2.1 所示的感知机组成，不过现代神经网络更多使用的是 S 型神经元模型。S 型神经元类似于感知机，但 S 型神经元权重和偏置的微小改动只引起输出的微小变化。

![图2.1 感知机模型](https://ufile.freewisdom.cn/resources/605a0101/perceptron.png)

<center>图2.1 感知机模型</center>

S型神经元有多个输入，表示为 $x_1,x_2,x_3,...$，对每个输入有权重 $w_1,w_2,w3,...$，以及一个总的偏置 $b$，其输出为 $\sigma(w\cdot x+b)$，$\sigma$ 为激活函数，也被称为 S 型函数，其定义为：
$$
\sigma(z)=\frac{1}{1-e^{-z}}
$$
总的来说上述神经元的输出为：
$$
\frac{1}{1-e^{-\left(\sum_jw_jx_j+b\right)}}
$$
一个简单神经网络如图2.2 所示，最左边的称为输入层，最右边为输出层，中间的一层则被称为隐藏层。输入层设计很直接，例如我们可以将图片像素的强度进行编码作为输入神经元来设计网络，若图像是一个 32 × 32 的灰度图像，那么我们会需要 1024 = 32 × 32 个输入神经元，像素值归一化到 0 和 1 之间作为神经元的输入。输出层可以只包含一个神经元，用于判断图片的类别，例如输出值大于 0.5 表示图片是我们的目标类别，反之则不是。隐藏层的设计需要大量的研究和思考，才能使得神经网络的行为符合人们的期望。深度学习包含许多层隐藏层，层数越多就越复杂，但能达到效果就越好，越能够模拟人脑的工作机制。当今最流行的深度学习神经网络之一深层卷积神经网络对图像处理效果很好，很适合解决目标检测中定位和分类问题。

![图2.2 简单的神经网络模型](https://ufile.freewisdom.cn/resources/605a0101/simple-nerual-net.png)

<center>图2.2 简单的神经网络模型</center>

对于图像来说，像素间的距离与其相似性有很强的关系，这表明两个距离较近的像素相比于距离较远的像素更为相似，人类视觉的单个神经元也是只对完整视野的一小部分进行响应，于是卷积神经网络采用局部感受域的概念。我们把输入像素连接到一个隐藏神经元层，但不会把每个输入像素连接到每个隐藏神经元，而是把输入图像进行局部区域的连接。例如， 一个 3×3 的区域，即 9 个输入像素，我们把这 9 个像素连接到第一个隐藏层的一个神经元，这个神经元学习这个局部域。如图2.3 所示，之后我们会在整个输入图像上交叉移动局部感受域，相当于卷积运算。对于每个局部感受域，在第一个隐藏层中有一个不同的隐藏神经元。如果我们输入图像是 5×5，局部域为 3×3，则隐藏层中会有 3×3 个神经元，我们还可以选择不同的移动步幅调整网络的输出。我们把从输入层到隐藏层的映射称为一个特征映射，实际的网络有更多的特征映射从而完成目标的识别。

![图2.3 移动局部感受域](https://ufile.freewisdom.cn/resources/605a0101/convolution.png)

<center>图2.3 移动局部感受域</center>

卷积神经网络还包含池化层（Pooling layer），利用非线性下采样（down-sampling）来减小特征图尺寸。池化层一般紧跟在卷积层之后，目的是简化卷积层输出的特征信息。常见的池化层为最大池化（max-pooling）和平均池化（average-pooling），两者区别如图2.4 所示。卷积神经网络最后使用全连接层，全连接层将池化层的每一个神经元连接到每一个输出神经元，所有这些小的单元组合起来形成了卷积神经网络。最后，我们将用梯度下降和反向传播来训练卷积神经网络。

![图2.4 最大值池化与平均池化](https://ufile.freewisdom.cn/resources/605a0101/pooling.png)

<center>图2.4 最大值池化与平均池化</center>

### 2.2 YOLO系列算法

YOLO 系列[18,19,20,21]从 v1 到 v4，性能和效率不断提升。YOLO v3 是 YOLO 的作者 J.Redmon 改进的最后一个版本，YOLO v4 则由 A.Bochkovskiy 等人改进。

![图2.5 YOLOv3网络结构（MS-COCO数据集）](https://ufile.freewisdom.cn/resources/605a0101/yolo-net-arch.png)

<center>图2.5 YOLO v3 网络结构（MS-COCO数据集）</center>

YOLO v3 主干网络为 Darknet-53，但没有第 53 层全连接层，同时作者 J. Redmon 为了降低池化对梯度的不良影响舍弃了池化操作，下采样采用步幅（stride）为 2 的卷积核来实现。主干网络的每一个卷积部分都使用了特有的CBL结构，由卷积层、批次归一化层、Leaky ReLU 组成，激活函数使用 Leaky ReLU，定义如下：
$$
\sigma(x) = max(0.01x, x)
$$
ResX 结构由由一个 CBL 结构和 X 个残差组件Res unit结构构成，每个 ResX 结构的第一个的 CBL 都起到下采样的作用，因此经过 5 次 Res 模块后，实现了 32 倍的下采样，借助残差结构让网络可以构建的更深。网络中还有上采样操作，例如若使用 32 倍降采样后的特征，这就导致深层特征的大小太小，利用上采样把 32 倍降采样得到的特征图的大小提升一倍，达到 16 倍下采样后的维度，之后通过 Concat 操作进行张量拼接，使得 16 倍的下采样的特征图能够利用深层特征进行检测。检测网络参考特征金字塔网络（Feature pyramid networks，FPN）[23]引入多尺度预测，将检测层数由 1 增加到 3，对应于 3 个不同尺度的特征图，将高层的特征信息通过上采样的方式进行传递融合，很好的融合了上下文特征信息，提高了检测小目标的能力和定位准确度。YOLO v3 采用 K-means 聚类的方法得到锚定框的尺寸，共有 9 个锚定框，按尺寸大小分给 3 个不同尺度的检测层。YOLO v3 的损失函数由定位损失、置信度损失、分类损失三部分构成，定位损失相比于 YOLO v1 会给预测框的平方和损失乘以由真实框得到权重系统以代替为了平衡大小框而进行的平方根运算；分类损失由 YOLO v2 的 softmax 损失改成二分类的交叉熵损失，从而可以对目标进行多标签预测。

YOLO v4 借鉴许多成果的研究成果进行了改进，有一个改进是是把 IoU 替换成了 CIoU（Complete-IoU），采用 CIoU 不仅加快收敛速度，还提高了预测框精度。采用 CIoU 后相比于 IoU 在 MS-COCO 数据集下提升了大约 3% 的 AP[24]，CIoU 基于 DIoU（Distance-IoU）[24]改进，C/DIoU 效果比 GIoU（Generalized-IoU）[25]更好。若 P 为预测框，G 为 GT（Ground Truth）框，C 是 P 和 G 的最小外接矩形（图2.6）：

![图2.6 预测框与 GT框](https://ufile.freewisdom.cn/resources/605a0101/iou.png)

<center>图2.6 预测框与 GT框</center>

则 IoU Loss 可表示为：
$$
L_{IoU} = 1-\frac{|B\cap G|}{|B\cup G|}
$$
GIoU Loss 表示为：
$$
L_{GIoU}=1-IoU(P,G)+\frac{|C-P\cup G|}{|C|}
$$
DIoU Loss 表示为：
$$
L_{DIoU}=1-IoU(P,G)+\frac{\rho^2(\text{p},\text{g})}{c^2}
$$
其中，$\text{p},\text{g}$ 分别为 $P$ 和 $G$ 的中心点坐标，$\rho^2(\text{p},\text{g})$ 为 $\text{p},\text{g}$ 两点间的欧式距离，$c^2$ 表示 $C$ 的对角线长度。

CIoU Loss表示为：
$$
\begin{align}
L_{CIoU}&=1-IoU(P,G)+\frac{\rho^2(\text{p},\text{g})}{c^2}+\alpha v \\
\alpha&=\frac{v}{(1-IoU)+v} \\
v&=\frac{4}{\pi^2}[arctan(\frac{w^\text{g}}{h^\text{g}})-a rctan(\frac{w^\text{p}}{h^\text{p}})]
\end{align}
$$
其中，$ w^\text{p},h^\text{p}$ 为 $P$ 的宽和高，$w^\text{g},h^\text{g}$ 为 $G$ 的宽和高。我们可看到 IoU 主要考虑预测框和 GT框的重叠面积，GIoU 则适用于预测框与 GT框不重合时的情况，DIoU 在 GIOU 的基础上，考虑预测框中心点与 GT框中心点距离，而 CIoU 在 DIoU 的基础上，考虑预测框与GT框的宽高比。除 CIoU 之外，YOLO v4 还采用很多其它的优化技巧，在精度和速度方面都达到了很高的水准。本文将采用 G/D/CIoU 对 YOLO v3 进行优化，探究定位损失对模型的影响。
