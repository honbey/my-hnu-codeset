
## 开题报告

### 1、选题的目的、意义（理论、现实）和国内外研究概况

#### 1.1 选题的目的和意义

视觉作为人类最重要的人体感知方式，获取的信息约占人类接触到的外界信息的80%。人类已经习惯通过视觉获取图像信息进而处理这些信息。图像是包含信息量较多的一种载体，互联网中有一半以上的流量用于传输图像数据；同时各种图像传感器被应用到人类日常生活中的方方面面，比如手机摄像头、视频监控、CT扫描仪等，仅仅依靠人眼无法处理不同领域中庞大的图像信息，这就必须利用计算机视觉来处理这些传感器传来的数以EB计的信息。计算机视觉的本质是利用计算机配合传感器替代人眼的功能，从生物学角度看，旨在构建人类视觉系统的计算模型；从工程学角度看，旨在构建一个可以执行人类视觉可执行的某些任务的系统[1]。

计算机视觉任务包括目标检测、目标跟踪、图像分割、图像检索、行为识别等，其中目标检测是其它更复杂的任务的基石，主要目的是找出图像中所有感兴趣的目标物体，确定它们的类别并用直观的边界框确定其位置。目标检测融合了图像处理、特征提取、深度学习等多个研究领域的前沿技术，是计算机视觉领域的核心问题之一。由于各种目标有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域极具挑战性的课题。

目前目标检测已广泛应用于自动驾驶、机器人视觉、视频监控等计算机视觉任务中[2]。在自动驾驶任务中，自动车辆需要对采集的图像信息进行处理，识别交通标志、车辆、行人等，精确而实时的目标识别系统对于保障安全驾驶至关重要；在机器人视觉任务中，机器人对真实人类的动作、行为及运动进行识别并产生相应的反馈，从而实现人机交互；在视频监控任务中，如果还采用事后查看和人工监督的方法将无法应对日益增加的视频数据，利用目标检测技术可以对人和物体进行识别，可以快速发现可疑人员，记录人员行为，实现智能化监控。我们知道，在公共场所佩戴口罩可以防止各种呼吸道疾病的传播，同时也能一定程度上的过滤空气中的污染物。随着新冠疫情常态化，如今许多人群密集的区域如电梯、超市、车站等都需要佩戴口罩，但通过人工检查口罩佩戴情况的方式会消耗大量的人力资源。我们可以利用目标识别技术实现一个口罩佩戴检测系统，对佩戴口罩不规范或未戴口罩的人予以提示，同时提高检测效率。

#### 1.2 国内外研究概况

##### 1.2.1 传统的目标检测

2001年P. Viola和M. Jones首次实现了人脸的实时检测[3]，他们发明的VJ检测器采用了最直接的滑动窗口方法：查看图像中所有可能的位置和比例，看能否找到包含人脸的窗口，为了匹配当时的计算能力，他们采用了“积分图像”、“特征选择”和“检测级联”三种技术提高检测速度。2004年，David Lowe完善[4]其于1999年提出的尺度不变特征变化匹配（Scale-Invariant Feature Transform，SIFT）[5]算法，该算法提出根据目标的部分的部分特征而不需要描述整个物体就可以实现识别任务的思想，完善后的SIFI算法更是对图像尺度和旋转、光照变化以及噪声具有鲁棒性。2005年N. Dalal和B.Triggs提出了方向梯度直方图(Histogram of Oriented Gradient，HOG)[6]，HOG改进了SIFI和形状上下文（Shape Contexts），为了平衡特征不变性和非线性，HOG描述符被设计在密集的均匀间隔单元网格上进行计算，并使用重叠的局部对比度归一化来进一步提高精度。此后，SIFT和HOG这样的手工特征是许多目标检测器的基础，结合一些机器学习分类算法如支持向量机（Support Vector Machine，SVM）有较好的检测效果。可变形部件的模型（Deformable Part-based Model，DPM）最初是由P. Felzenszwalb等[7]于2008年提出的，起初是作为HOG检测器的扩展，DPM采用“分而治之”的思想对目标进行检测，训练简单地看作是学习如何正确的分解对象，推理可以看作对不同对象的部件的检测集合。DPM应用“混合模型”、“硬负挖掘”、“边界盒回归”等技术提高检测精度。2010年R. Girshick等人对DPM进行改进[8,9]，引入了级联结构，使得DPM检测速度提高了10倍。2012年，G. E. Hinton和他的学生A. Krizhevsky提出的AlexNet在ImageNet比赛中取得的成就为目标检测算法提供了新思路，他们使用了深度卷积神经网络[10]。此后，目标识别算法开始以前所未有的速度发展。

##### 1.2.2 基于深度学习的目标检测

2006年，Hinton在《科学》杂志刊文提出了深度学习[11]的概念，但一直到2011年，深度学习才迎来大爆发，此后国际上许多知名公司如谷歌、微软、Facebook都积极建立研究院进行深度学习这方面的研究。国内紧跟国际潮流，许多公司如百度、阿里、腾讯、华为、小米等也在积极进行深度学习的研究，许多行业如交通[12]、医疗[13]、服务[14]也在积极应用深度学习。百度作为全球最大的中文搜索引擎提供商，利用其得天独厚的数据优势，率先成立国内深度学习研究院，2014年又在美国硅谷成立人工智能实验室，2016年面向全球开源国内首个开源深度学习框架“PaddlePaddle（飞浆）”，并成功在国内外深度学习领域取得了认可。此外，国内许多高校也纷纷开设深度学习课程，并进行相关研究，2020年，清华大学发布国内首个由高校主导并开源的深度学习框架“Jittor（计图）“，推动了深度学习框架国产化的进程。

人工神经网络是模拟人脑神经元的功能的网络结构，深度学习则包含多层人工神经网络。最早的人工神经网络起源于1943年的MCP人工神经元模型，建立了首个神经网络的数学模型。1958年感知机诞生，1989年，G. E. Hinton提出了采用非线性激活函数的反向传播算法，有力的推动了神经网络的研究，同年，Y. LuCun为了检测手写数字[15]发明了LeNet。1998年由LeCun设计的的LeNet5[16]模型标志着卷积神经网络（Convolutional Neural Networks，CNN）真正面世。2012年基于CNN的AlexNet的成就使得大量研究者纷纷研究CNN，研究出许多基于CNN的目标检测算法，如图1所示。

![图1 从传统目标检测到基于深度学习的目标检测](https://ufile.freewisdom.cn/resources/605a0101/obj-det-development.png)

<center>图1 从传统目标检测到基于深度学习的目标检测</center>

2014年由R. Girshick等提出的R-CNN[17]通过选择性搜索提取一组对象候选框，每个候选框都被重新调整成一个固定大小的图像输入到CNN中，最后，利用SVM分类器对每个区域内的目标进行预测。R-CNN会在大量（每张图片2000多个候选框）重叠的候选框上进行冗余的特征计算，导致检测速度极慢。虽然之后研究者不变改进两阶段检测器，但实时目标检测效果还是差强人意。

2016年，J. Redmon等人提出的YOLO（You Only Look Once）[18]算法开创了基于回归方法的深度学习目标检测算法，同时 YOLO也是一种单阶段目标检测算法，实现了端到端的检测。YOLO将全图划分成单元格，每个单元格需要对落入其中的目标进行检测，一次性预测所有单元格所含目标的边界框、定位置信度和类别概率。YOLO可以处理每秒45帧的视频，同时还能有比较好的检测精度，在PASCAL VOC数据集上mAP能达到63.4%。随后研究者们也推出了其它的单阶段目标检测算法，如SSD（Single Shot MultiBox Detector）[22]等。2017年提出的YOLOv2[19]在YOLO的基础上修改了基础网络结构，采用Darknet-19减少了计算量；增加了批次归一化层，引入了维度聚类的Anchor Box机制，采用高分辨率分类器，采用规约的offset预测边界框位置，这些改进在提高检测速度的同时显著提升了检测精度，在VOC数据集上在和YOLOv1差不多的速度下mAP达到78.6%。2018年，YOLOv3[20]再次改进了YOLO算法，主干网络采用Darknet-53，减少了浮点数运算量；引入特征金字塔多尺度预测以提高定位精准度，采用多标签分类，同时优化损失函数，提高了小目标的检测效果。YOLOv3在MS-COCO数据集320×320分辨率上，YOLOv3处理每张图片仅需要22ms，比同分辨率情况的SSD快3倍，同时mAP还比SSD高，达到了28.2%。2020年A. Bochkovskiy等人改进的YOLOv4[21]结合计算机视觉领域多篇优秀论文对YOLO进行改进，相比YOLOv3提高10%的AP和12%的FPS，同时使得训练速度更快且更适合于单GPU训练。



### 2、本课题的理论依据、研究内容和研究方法、步骤及进度安排

#### 2.1 本选题的理论依据

##### 2.1.1 神经网络与深度学习

最简单的人工神经网络如图2所示的感知机组成，不过现代神经网络更多使用的是S型神经元模型。S型神经元类似于感知机，但S型神经元权重和偏置的微小改动只引起输出的微小变化。

![图2 感知机模型](https://ufile.freewisdom.cn/resources/605a0101/perceptron.png)

<center>图2 感知机模型</center>

S型神经元有多个输入，表示为$x_1,x_2,x_3,...$，对每个输入有权重$w_1,w_2,w3,...$，以及一个总的偏置$b$，其输出为$\sigma(w\cdot x+b)$，$\sigma$为激活函数，也被称为S型函数，其定义为：
$$
\sigma(z)=\frac{1}{1-e^{-z}}
$$
总的来说上述神经元的输出为：
$$
\frac{1}{1-e^{-\left(\sum_jw_jx_j+b\right)}}
$$
一个简单神经网络如图3所示，最左边的称为输入层，最右边为输出层，中间的一层则被称为隐藏层。输入层设计很直接，例如我们可以将图片像素的强度进行编码作为输入神经元来设计网络，若图像是一个 32 × 32 的灰度图像，那么我们会需要 1024 = 32 × 32 个输入神经元，像素值归一化到0和1之间作为神经元的输入。输出层可以只包含一个神经元，用于判断图片的类别，例如输出值大于0.5表示图片是我们的目标类别，反之则不是。隐藏层的设计需要大量的研究和思考，才能使得神经网络的行为符合人们的期望。深度学习包含许多层隐藏层，层数越多就越复杂，但能达到效果就越好，越能够模拟人脑的工作机制。当今最流行的深度学习神经网络之一深层卷积神经网络对图像处理效果很好，很适合解决目标检测中定位和分类问题。

![图3 简单的神经网络模型](https://ufile.freewisdom.cn/resources/605a0101/simple-nerual-net.png)

<center>图3 简单的神经网络模型</center>

对于图像来说，像素间的距离与其相似性有很强的关系，这表明两个距离较近的像素相比于距离较远的像素更为相似，人类视觉的单个神经元也是只对完整视野的一小部分进行响应，于是卷积神经网络采用局部感受域的概念。我们把输入像素连接到一个隐藏神经元层，但不会把每个输入像素连接到每个隐藏神经元，而是把输入图像进行局部区域的连接。例如， 一个3×3的区域，即9个输入像素，我们把这9个像素连接到第一个隐藏层的一个神经元，这个神经元学习这个局部域。如图4所示，之后我们会在整个输入图像上交叉移动局部感受域，相当于卷积运算。对于每个局部感受域，在第一个隐藏层中有一个不同的隐藏神经元。如果我们输入图像是5×5，局部域为3×3，则隐藏层中会有3×3个神经元，我们还可以选择不同的移动步幅调整网络的输出。我们把从输入层到隐藏层的映射称为一个特征映射，实际的网络有更多的特征映射从而完成目标的识别。

![图4 移动局部感受域](https://ufile.freewisdom.cn/resources/605a0101/convolution.png)

<center>图4 移动局部感受域</center>

卷积神经网络还包含池化层（Pooling layer），利用非线性下采样（down-sampling）来减小特征图尺寸。池化层一般紧跟在卷积层之后，目的是简化卷积层输出的特征信息。常见的池化层为最大池化（max-pooling）和平均池化（average-pooling），两者区别如图5所示。卷积神经网络最后使用全连接层，全连接层将池化层的每一个神经元连接到每一个输出神经元，所有这些小的单元组合起来形成了卷积神经网络。最后，我们将用梯度下降和反向传播来训练卷积神经网络。

![图5 最大值池化与平均池化](https://ufile.freewisdom.cn/resources/605a0101/pooling.png)

<center>图5 最大值池化与平均池化</center>

##### 2.1.2 YOLO系列算法

YOLO系列[18,19,20,21]从v1到v4，性能和效率不断提升。YOLOv3是YOLO的作者J. Redmon改进的最后一个版本，YOLOv4则由A. Bochkovskiy等人改进。

![图6 YOLOv3网络结构（MS-COCO数据集）](https://ufile.freewisdom.cn/resources/605a0101/yolo-net-arch.png)

<center>图6 YOLOv3网络结构（MS-COCO数据集）</center>

YOLOv3主干网络为Darknet-53，但没有第53层全连接层，同时作者J. Redmon为了降低池化对梯度的不良影响舍弃了池化操作，下采样采用步幅（stride）为2的卷积核来实现。主干网络的每一个卷积部分都使用了特有的CBL结构，由卷积层、批次归一化层、Leaky ReLU组成，激活函数使用Leaky ReLU，定义如下：
$$
\sigma(x) = max(0.01x, x)
$$
ResX结构由由一个CBL结构和X个残差组件Res unit结构构成，每个ResX结构的第一个的CBL都起到下采样的作用，因此经过5次Res模块后，实现了32倍的下采样，借助残差结构让网络可以构建的更深。网络中还有上采样操作，例如若使用32倍降采样后的特征，这就导致深层特征的大小太小，利用上采样把32倍降采样得到的特征图的大小提升一倍，达到16倍下采样后的维度，之后通过Concat操作进行张量拼接，使得16倍的下采样的特征图能够利用深层特征进行检测。检测网络参考特征金字塔网络（Feature pyramid networks，FPN）[23]引入多尺度预测，将检测层数由1增加到3，对应于3个不同尺度的特征图，将高层的特征信息通过上采样的方式进行传递融合，很好的融合了上下文特征信息，提高了检测小目标的能力和定位准确度。YOLOv3采用K-means聚类的方法得到锚定框的尺寸，共有9个锚定框，按尺寸大小分给3个不同尺度的检测层。YOLOv3的损失函数由定位损失、置信度损失、分类损失三部分构成，定位损失相比于YOLOv1会给预测框的平方和损失乘以由真实框得到权重系统以代替为了平衡大小框而进行的平方根运算；分类损失由YOLOv2的softmax损失改成二分类的交叉熵损失，从而可以对目标进行多标签预测。

YOLOv4借鉴许多成果的研究成果进行了改进，有一个改进是是把IoU替换成了CIoU（Complete-IoU），采用CIoU不仅加快收敛速度，还提高了预测框精度。采用CIoU后相比于IoU在MS-COCO数据集下提升了大约3%的AP[24]，CIoU基于DIoU（Distance-IoU）[24]改进，C/DIoU效果比GIoU（Generalized-IoU）[25]更好。若P为预测框，G为GT框，C是P和G的最小外接矩形（图7）：

![图7 预测框与GT框](https://ufile.freewisdom.cn/resources/605a0101/iou.png)

<center>图7 预测框与GT框</center>

则IoU损失可表示为：
$$
L_{IoU} = 1-\frac{|B\cap G|}{|B\cup G|}
$$
GIoU损失表示为：
$$
L_{GIoU}=1-IoU(P,G)+\frac{|C-P\cup G|}{|C|}
$$
DIoU损失表示为：
$$
L_{DIoU}=1-IoU(P,G)+\frac{\rho^2(\text{p},\text{g})}{c^2}
$$
其中，$\text{p},\text{g}$ 分别为 $P$ 和 $G$ 的中心点坐标，$\rho^2(\text{p},\text{g})$ 为 $\text{p},\text{g}$ 两点间的欧式距离，$c^2$ 表示 $C$ 的对角线长度。

CIoU损失表示为：
$$
\begin{align}
L_{CIoU}&=1-IoU(P,G)+\frac{\rho^2(\text{p},\text{g})}{c^2}+\alpha v \\
\alpha&=\frac{v}{(1-IoU)+v} \\
v&=\frac{4}{\pi^2}[arctan(\frac{w^\text{g}}{h^\text{g}})-a rctan(\frac{w^\text{p}}{h^\text{p}})]
\end{align}
$$
其中，$ w^\text{p},h^\text{p}$为 $P$ 的宽和高，$w^\text{g},h^\text{g}$ 为 $G$ 的宽和高。我们可看到IoU主要考虑预测框和GT（Ground Truth）框的重叠面积，GIoU则适用于预测框与GT框不重合时的情况，DIoU在GIOU的基础上，考虑预测框中心点与GT框中心点距离，而CIoU在DIoU的基础上，考虑预测框与GT框的宽高比。除CIoU之外，YOLOv4还采用很多其它的优化技巧，在精度和速度方面都达到了很高的水准。

#### 2.2 本选题研究内容

本课题主要研究YOLOv3模型，首先会对深入学习YOLOv3模型，理解其原理后复现此模型，针对YOLOv3模型采用IoU计算定位损失，将参考YOLOv4引入C/D/GIoU进行优化，最后实现一个实时的目标检测系统。研究内容细化如下：

（1）阅读YOLO系列以及目标检测相关的论文以熟悉YOLO模型和目标检测技术，了解YOLO与其它目标检测技术的异同，主要学习YOLOv3算法背后的原理，同时参考开源代码进行模型的复现实验。

（2）YOLOv3相比于YOLOv1, v2有很大的改进，但是还是有很大的提升空间，本文将参考YOLOv4对IoU的改进，使用C/D/GIoU优化YOLOv3，采用标准数据集进行实验，查看经过小优化后的YOLOv3的检测效果，然后对实验结果进行分析。

（3）研究YOLO模型的实际应用，主要是利用YOLOv3实现一个实时的目标检测系统，功能是检测口罩佩戴情况，佩戴情况分为好（good）、坏（bad）和无（none），将使用网络上的人脸数据集训练网络。

#### 2.3 研究方法

（1）文献研究法：通过图书馆、互联网、电子资源数据库等途径查阅文献，了解深度学习和目标检测的相关知识，理清目标检测技术的发展脉络及研究现状，学习YOLO模型的有关理论知识，同时为设计目标检测系统提供思路和参照。

（2）实验研究法：通过已有的深度学习框架TensorFlow2.0复现YOLO模型，进一步理解YOLO模型的原理。针对YOLOv3存在的改进空间，选取C/D/GIoU对其进行改进，使用MS-COCO或PASCAL VOC数据集进行对比实验，观察检测速度以及精度的变化。针对本文设计的口罩佩戴检测系统进行多次实验，检验设计成果。

#### 2.4 步骤及进度安排

2021年1月 - 2021年1月 收集资料，阅读文献，撰写毕业设计开题报告。

2021年2月 - 2021年3月 根据研究内容进行实验，记录实验过程。

2021年3月 - 2021年3月 提交中期检查，完成论文草稿。

2021年3月 - 2021年4月 修改论文，完成论文定稿并提交导师审核。

2021年4月 - 2021年5月 完成最终稿，打印论文并进行答辩准备。



### 3、本课题的重点、难点，预期结果和成果形式

#### 3.1 本课题的重点、难点

本课题的重点为深度学习和YOLO目标检测模型。深度学习利用神经网络帮助我们利用数据集进行训练，其核心是对人脑思维深层次学习的模拟，实现计算机模拟人脑的抽象认知过程。借助深度学习，目标检测技术飞速发展，各种算法与模型被提出并拥有不错的效果，其中有的模型准确率已经超过了人类。YOLO目标检测模型是一种单步检测器，拥有非常好的实时检测性能，能够很方便的应用到实际生活中，是本课题主要的研究对象。

本课题的难点有深度学习的反向传播算法、YOLO模型的网络结构。深度学习需要一定的数学基础，若要理解深度学习，至少要知道导数和相关的函数概念才能够理解反向传播算法，理解了反向传播算法，才能对深度学习学习的过程有一个清晰的认识，反向传播算法主要是求损失函数关于权重、偏置以及其它需要学习的参数的偏导，关系到如何通过改变权重和偏置来改变整个网络的行为，偏导数的表达式比较复杂，容易劝退初学者；其中还有损失函数，损失函数的意义以及作用也需要花费大量时间才能理解透彻；YOLO模型的网络结构在YOLOv3版本提升了网络结构的深度，使得网络结构并不是一目了然，理解起来需要更强的逻辑思维能力。

#### 3.2 预期结果和成果形式

##### 3.2.1 预期结果

完成毕业设计论文，同时实现一个实时的目标检测系统，能够读取摄像头视频流对特定目标进行检测。

##### 3.2.2 成果形式

（1）论文

（2）计算机程序



### 4、计划完成时间

2021年5月10日