## 参考文献

[1] T. S. Huang. Computer Vision: Evolution and Promise[OL]. http://cds.cern.ch/record/400313/files/p21.pdf, 1996.

[2] Zhengxia Zou, Zhenwei Shi, Yuhong Guo, et al. Object Detection in 20 Years: A Survey[J]. arXiv:1905.05055, 2019.

[3] P. Viola, M. Jones. Rapid object detection using a boosted cascade of simple features[C].  Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. 2001:  511-518.

[4] D. G. Lowe. Distinctive Image Features from Scale-Invariant Key-points[J]. International Journal of Computer Vision, vol. 60(2), 2004: 91-110.

[5] D. G. Lowe. Object recognition from local scale-invariant features[C]. Proceedings of the Seventh IEEE International Conference on Computer Vision, vol. 2, 1999: 1150-1157.

[6] N. Dalal, B. Triggs. Histograms of oriented gradients for human detection[C]. Computer Vision and Pattern Recognition,  vol. 1, 2005: 886–893.

[7] P. Felzenszwalb, D. McAllester, D. Ramanan. A discriminatively trained, multiscale, deformable part model[C]. Computer Vision and Pattern Recognition, 2008: 1–8.

[8] P. F. Felzenszwalb, R. B. Girshick, D. McAllester. Cascade object detection with deformable part models[C]. Computer vision and pattern recognition, 2010: 2241–2248.

[9] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, et al. Object detection with discriminatively trained part-based models. IEEE transactions on pattern analysis and machine intelligence, vol. 32(9), 2010: 1627–1645.

[10] A. Krizhevsky, I. Sutskever, G. E. Hinton. Imagenet classification with deep convolutional neural networks,” in Advances in neural information processing systems, 2012, pp. 1097–1105.

[11] G. E. Hinton, R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks[J]. Science, vol. 313(5786), 2006: 504-507

[12] 许辉, 王九胜, 杨川等. 基于高分影像与深度学习方法的路网提取技术研究与应用[J]. 公路, 65(09), 2020: 204-207.

[13] 凌铖. 基于生成对抗网络的医学图像数据增强技术研究[D]. 电子科技大学, 2020.

[14] 上海艾瑞市场咨询有限公司. 中国AI基础数据服务行业发展报告[C]. 上海艾瑞市场咨询有限公司, 04, 2020:26-26.

[15] Y. LeCun, B. Boser, J. S. Denkeret  et al. Backpropagation Applied to Handwritten Zip Code Recognition[J]. Neural Computation, vol. 1(4), 1989: 541-551.

[16] Y. LeCun, L. Bottou, Y. Bengio, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, vol. 86(11), 1998: 2278-2324.

[17] R. Girshick, J. Donahue, T. Darrell, et al. Rich feature hierarchies for accurate object detection and se- mantic segmentation[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2014: 580– 587.

[18] J. Redmon, S. Divvala, R. Girshick. You only look once: unified, real-time object detection[J]. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.

[19] J. Redmon, Ali Farhadi. Yolo9000: better, faster, stronger[J]. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.

[20] J. Redmon, A. Farhadi. Yolov3: an incremental improvement[J]. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.

[21] A. Bochkovskiy, C. Y. Wang,  H. Y. Liao. Yolov4: optimal speed and accuracy of object detection[J]. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.

[22] W. Liu, D. Anguelov, D. Erhan, et al. SSD: Single shot multibox detector[C]. European conference on computer vision. 2016: 21–37.

[23] T. -Y. Lin, P. Dollar, R. B. Girshick, et al. Feature pyramid networks for object detection[J]. CVPR, vol. 1(2), 2017: 4-4.

[24] Zhaohui Zheng, Ping Wang, Wei Liu, et al. Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression[J]. The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020), 2020: 12993-13000.

[25] Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, et al. Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression[J]. CVPR 2019, 2019: 658-666.



## 文献解读
[1](http://cds.cern.ch/record/400313/files/p21.pdf)
[2-1](https://arxiv.org/abs/1905.05055v2)
[2-2](https://blog.csdn.net/clover_my/article/details/92794719)
3: WebVPN IEEE
[4-1](https://www.researchgate.net/publication/200038910_Distinctive_Image_Features_from_Scale-Invariant_Keypoints)
[4-2](https://www.cnblogs.com/cuteshongshong/archive/2012/05/25/2506374.html)
[5](https://www.computer.org/csdl/proceedings-article/iccv/1999/01641150/12OmNxEjY4f)
6-17
18-21: yolo v1-4 
21-23
[24](https://zhuanlan.zhihu.com/p/159209199)
[25](https://zhuanlan.zhihu.com/p/143747206)


## 其它参考文献

[15] K. He, X. Zhang, S. Ren, et al. Spatial pyra- mid pooling in deep convolutional networks for visual 28 recognition[C]. European conference on computer vision, 2014: 46–361.

[16] R. Girshick. Fast R-CNN[C]. Proceedings of the IEEE inter-national conference on computer vision, 2015: 1440–1448.

[17] S. Ren, K. He, R. Girshick, et al. Faster R-CNN: Towards real-time object detection with region proposal networks[C]. Advances in neural information processing systems, 2015: 91–99.

[24] T. -Y. Lin, P. Goyal, R. Girshick, et al. Focal loss for dense object detection[J]. IEEE transactions on pattern analysis and machine intelligence, 2018.

## 附录
### 文献类型

|类型|简称|全称|
|--------|--|-------------------|
|期刊    |[J]|（journal）|
|专著    |[M]|（monograph）|
|论文集   |[C]|（collected papers）|
|学位论文 |[D]|（dissertation）|
|专利    |[P]|（patent）|
|技术标准 |[S]|（standardization）|
|报纸    |[N]|（newspaper article）|
|科技报告 |[R]|（report）|

参考文献写作规范说明
根据国家标准 GB 3469规定，以单字母方式标识以下各种参考文献类型：
论文集 报纸文章  期刊文章  学位论文  报告  标准  专利  汇编  参考工具
C N J D R S P G K
对于其他未说明的文献类型，建议采用单字母“Z”
对于数据库(database)、计算机程序(computer program)及电子公告(electronic bulletin board)等电子文献类型的参考文献，建议以下列双字母作为标志：
数据库 计算机程序 电子公告
DB  CP  EB

[序号] 主要责任者.文献题名[J].刊名(建议外文刊名后加ISSN号),年,卷(期):起止页码.
报纸文章
[序号] 主要责任者. 文献题名 [N]. 报纸名，出版日期 (版次).
标准(包括国际标准、国家标准、规范、法规等)
[序号] 主要责任者(任选).标准名称:标准编号[S]. 出版地(任选):出版者(任选),出版年(任选)

### 图中字体

- 英文 Source Sans Pro

- 中文 Noto Sans SC

### 参考链接
[计算机视觉资料](https://blog.csdn.net/seusong/article/details/4484220)

[计算机视觉论文推荐](https://www.zhihu.com/question/355566860)

[改进 YOLO 轻量化网络的口罩检测算法](https://kns.cnki.net/KXReader/Detail?TIMESTAMP=637468228772265625&DBCODE=CAPJ&TABLEName=CAPJLAST&FileName=JSGG20210118009&RESULT=1&SIGN=C1%2bzT14OcGAHOFBFu06zZvflvGU%3d&UID=WEEvREcwSlJHSldSdmVqMDh6a1dqeTZJWlkyREQ5aTFaeW05SG1INTRIaz0%3d%249A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!&PlatForm=kdoc)

[详解 YOLO](https://zhuanlan.zhihu.com/p/183261974)

[Yolov3边框预测分析](https://blog.csdn.net/qq_34199326/article/details/84109828)

[YOLOV3-损失函数及其源代码理解](https://blog.csdn.net/weixin_39753747/article/details/111516433)

[IOU/GIOU/DIOU](https://blog.csdn.net/leonardohaig/article/details/103394369)

### 测试视频
来源：[YouTube](https://www.youtube.com/watch?v=fY0f8GprQlE)
来源：[Bilibili](https://bilibili.com)
